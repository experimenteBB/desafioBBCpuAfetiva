{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "desafioBB.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS2-Wlg5NnDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install opencv-python --user\n",
        "#!pip install keras --user"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31rgZZQDN0kw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "9c15d020-11a4-4c1d-e1ad-55268541b30e"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Convolution2D\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "from keras.models import Sequential\n",
        "from keras.regularizers import l2\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers.advanced_activations import ELU\n",
        "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
        "from keras.optimizers import RMSprop, SGD, Adam, Adamax\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras import regularizers\n",
        "from keras.regularizers import l1\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import cv2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ4Eonr5OTFZ",
        "colab_type": "code",
        "outputId": "1f316f66-27ff-4ad2-d63b-d4acd62d6f5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGoeB7HSN47O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "width, height = 48, 48\n",
        "image_size = (width, height)\n",
        "num_features = 64\n",
        "num_labels = 5\n",
        "batch_size = 64\n",
        "epochs = 100\n",
        "\n",
        "num_filters = 10\n",
        "kernel_size=(4, 4)\n",
        "\n",
        "MODELPATH = '/content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5'\n",
        "MODELPATH2 = '/content/drive/My Drive/Colab Notebooks/desafioBB/models/model_inn_drop.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnLNQtwh8Uls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_full_df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/desafioBB/fer2013.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GtKGi46N610",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_csv_file(data):\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'), image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = pd.get_dummies(data['emotion']).as_matrix()\n",
        "    return faces, emotions\n",
        "\n",
        "\n",
        "mask_eliminate_disgust_fear = np.logical_and((dataset_full_df['emotion']!=int(1)),(dataset_full_df['emotion']!=int(2)))\n",
        "dataset_df = dataset_full_df.loc[mask_eliminate_disgust_fear].reset_index(drop=True)\n",
        "\n",
        "# Convertendo o interpretados para o modo BB\n",
        "# {0: \"Angry\", 1: \"Disgust\", 2: \"Fear\", 3: \"Happy\", 4: \"Sad\", 5: \"Surprise\", 6: \"Neutral\"}\n",
        "# 0-neutra; 1-feliz; 2-triste; 3-surpreso; e 4-bravo.\n",
        "dataset_df_feliz = (dataset_df['emotion']==int(3))*1\n",
        "dataset_df_triste = (dataset_df['emotion']==int(4))*2\n",
        "dataset_df_surpreso = (dataset_df['emotion']==int(5))*3\n",
        "dataset_df_bravo = (dataset_df['emotion']==int(0))*4\n",
        "\n",
        "dataset_df_bb = dataset_df_feliz + dataset_df_triste + dataset_df_surpreso + dataset_df_bravo\n",
        "# Apaga o atual para colocar o novo\n",
        "dataset_df['emotion'] = dataset_df['emotion']*0\n",
        "dataset_df['emotion'] = dataset_df['emotion']+dataset_df_bb\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yalqkj3yBwz7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "9dabe73f-1497-420e-bf38-c1cd291076f9"
      },
      "source": [
        "mask_training = (dataset_full_df['Usage']==\"Training\")\n",
        "mask_test = (dataset_full_df['Usage']==\"PublicTest\")\n",
        "mask_valid = (dataset_full_df['Usage']==\"PrivateTest\")\n",
        "\n",
        "train_raw = dataset_df.loc[mask_training].reset_index(drop=True)\n",
        "test_raw = dataset_df.loc[mask_test].reset_index(drop=True)\n",
        "valid_raw = dataset_df.loc[mask_valid].reset_index(drop=True)\n",
        "\n",
        "X_train, y_train = process_csv_file(train_raw)\n",
        "X_test, y_test = process_csv_file(test_raw)\n",
        "X_valid, y_valid = process_csv_file(valid_raw)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_YFyvAmN90h",
        "colab_type": "code",
        "outputId": "58d96c05-349e-4848-a073-c1d584bba199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Convolution2D(filters=16, kernel_size=(5, 5), padding='same',\n",
        "                        name='image_array', input_shape=(width,height,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(filters=16, kernel_size=(5, 5),\n",
        "                        strides=(2, 2), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(.25))\n",
        "\n",
        "model.add(Convolution2D(filters=32, kernel_size=(5, 5), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(filters=32, kernel_size=(5, 5),\n",
        "                        strides=(2, 2), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(.25))\n",
        "\n",
        "model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(filters=64, kernel_size=(3, 3),\n",
        "                        strides=(2, 2), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(.25))\n",
        "\n",
        "model.add(Convolution2D(filters=64, kernel_size=(1, 1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(filters=128, kernel_size=(3, 3),\n",
        "                        strides=(2, 2), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(.25))\n",
        "\n",
        "model.add(Convolution2D(filters=256, kernel_size=(1, 1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(filters=128, kernel_size=(3, 3),\n",
        "                        strides=(2, 2), padding='same'))\n",
        "\n",
        "model.add(Convolution2D(filters=256, kernel_size=(1, 1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(filters=num_labels, kernel_size=(3, 3),\n",
        "                        strides=(2, 2), padding='same'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "image_array (Conv2D)         (None, 48, 48, 16)        416       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 48, 48, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 16)        6416      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 32)        12832     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 12, 12, 32)        25632     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 12, 12, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 12, 12, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 12, 12, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 6, 6, 64)          36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 6, 6, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 6, 6, 64)          4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 6, 6, 64)          256       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 3, 3, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 3, 3, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 3, 3, 256)         33024     \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 3, 3, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 2, 2, 128)         295040    \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 2, 2, 256)         33024     \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 2, 2, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 1, 1, 5)           11525     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 5)                 0         \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 555,061\n",
            "Trainable params: 553,205\n",
            "Non-trainable params: 1,856\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcXvI_xVIGhp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "1e541672-fa2e-4197-afbe-eb18ea193348"
      },
      "source": [
        "model.compile(loss=categorical_crossentropy,\n",
        "              optimizer=Adam(lr=0.0001, decay=1e-6),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3, verbose=1)\n",
        "early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=8, verbose=1, mode='auto')\n",
        "checkpointer = ModelCheckpoint(MODELPATH, monitor='val_loss', verbose=1, save_best_only=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-5K_B01M10H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b2f949ab-e2ef-493c-8f17-b33cae7bb3db"
      },
      "source": [
        "model.fit(np.array(X_train), np.array(y_train),\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(np.array(X_test), np.array(y_test)),\n",
        "          shuffle=True,\n",
        "          callbacks=[lr_reducer, early_stopper, checkpointer])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 28709 samples, validate on 1510 samples\n",
            "Epoch 1/100\n",
            "28709/28709 [==============================] - 22s 760us/step - loss: 1.5463 - acc: 0.3355 - val_loss: 1.3704 - val_acc: 0.4285\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.37043, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 2/100\n",
            "28709/28709 [==============================] - 18s 625us/step - loss: 1.4051 - acc: 0.4137 - val_loss: 1.2956 - val_acc: 0.4742\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.37043 to 1.29564, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 3/100\n",
            "28709/28709 [==============================] - 18s 626us/step - loss: 1.3386 - acc: 0.4453 - val_loss: 1.2833 - val_acc: 0.4662\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.29564 to 1.28327, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 4/100\n",
            "28709/28709 [==============================] - 18s 625us/step - loss: 1.2873 - acc: 0.4707 - val_loss: 1.1945 - val_acc: 0.5113\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.28327 to 1.19448, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 5/100\n",
            "28709/28709 [==============================] - 18s 626us/step - loss: 1.2497 - acc: 0.4893 - val_loss: 1.1672 - val_acc: 0.5185\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.19448 to 1.16724, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 6/100\n",
            "28709/28709 [==============================] - 18s 624us/step - loss: 1.2148 - acc: 0.5020 - val_loss: 1.1295 - val_acc: 0.5430\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.16724 to 1.12948, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 7/100\n",
            "28709/28709 [==============================] - 18s 627us/step - loss: 1.1872 - acc: 0.5200 - val_loss: 1.1326 - val_acc: 0.5358\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 1.12948\n",
            "Epoch 8/100\n",
            "28709/28709 [==============================] - 18s 625us/step - loss: 1.1580 - acc: 0.5325 - val_loss: 1.1080 - val_acc: 0.5470\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.12948 to 1.10803, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 9/100\n",
            "28709/28709 [==============================] - 18s 625us/step - loss: 1.1345 - acc: 0.5419 - val_loss: 1.0547 - val_acc: 0.5689\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.10803 to 1.05469, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 10/100\n",
            "28709/28709 [==============================] - 18s 627us/step - loss: 1.1167 - acc: 0.5485 - val_loss: 1.0679 - val_acc: 0.5596\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.05469\n",
            "Epoch 11/100\n",
            "28709/28709 [==============================] - 18s 626us/step - loss: 1.0932 - acc: 0.5582 - val_loss: 1.0267 - val_acc: 0.5828\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.05469 to 1.02667, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 12/100\n",
            "28709/28709 [==============================] - 18s 625us/step - loss: 1.0749 - acc: 0.5688 - val_loss: 1.0253 - val_acc: 0.5947\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.02667 to 1.02528, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 13/100\n",
            "28709/28709 [==============================] - 18s 630us/step - loss: 1.0599 - acc: 0.5736 - val_loss: 1.0122 - val_acc: 0.6040\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.02528 to 1.01219, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 14/100\n",
            "28709/28709 [==============================] - 18s 624us/step - loss: 1.0446 - acc: 0.5806 - val_loss: 0.9871 - val_acc: 0.6026\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.01219 to 0.98714, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 15/100\n",
            "28709/28709 [==============================] - 18s 625us/step - loss: 1.0320 - acc: 0.5871 - val_loss: 0.9658 - val_acc: 0.6099\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.98714 to 0.96583, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 16/100\n",
            "28709/28709 [==============================] - 18s 623us/step - loss: 1.0157 - acc: 0.5931 - val_loss: 0.9547 - val_acc: 0.6205\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.96583 to 0.95470, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 17/100\n",
            "28709/28709 [==============================] - 18s 622us/step - loss: 1.0108 - acc: 0.5940 - val_loss: 0.9552 - val_acc: 0.6285\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.95470\n",
            "Epoch 18/100\n",
            "28709/28709 [==============================] - 18s 623us/step - loss: 0.9924 - acc: 0.6063 - val_loss: 0.9331 - val_acc: 0.6371\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.95470 to 0.93313, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 19/100\n",
            "28709/28709 [==============================] - 18s 620us/step - loss: 0.9848 - acc: 0.6076 - val_loss: 0.9317 - val_acc: 0.6384\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.93313 to 0.93172, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 20/100\n",
            "28709/28709 [==============================] - 18s 617us/step - loss: 0.9767 - acc: 0.6087 - val_loss: 0.9436 - val_acc: 0.6325\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.93172\n",
            "Epoch 21/100\n",
            "28709/28709 [==============================] - 18s 615us/step - loss: 0.9612 - acc: 0.6199 - val_loss: 0.9058 - val_acc: 0.6497\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.93172 to 0.90576, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 22/100\n",
            "28709/28709 [==============================] - 18s 616us/step - loss: 0.9576 - acc: 0.6195 - val_loss: 0.9144 - val_acc: 0.6411\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.90576\n",
            "Epoch 23/100\n",
            "28709/28709 [==============================] - 18s 617us/step - loss: 0.9463 - acc: 0.6248 - val_loss: 0.9029 - val_acc: 0.6464\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.90576 to 0.90292, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 24/100\n",
            "28709/28709 [==============================] - 18s 619us/step - loss: 0.9452 - acc: 0.6253 - val_loss: 0.9002 - val_acc: 0.6457\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.90292 to 0.90024, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 25/100\n",
            "28709/28709 [==============================] - 18s 623us/step - loss: 0.9370 - acc: 0.6284 - val_loss: 0.8824 - val_acc: 0.6570\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.90024 to 0.88238, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 26/100\n",
            "28709/28709 [==============================] - 18s 625us/step - loss: 0.9267 - acc: 0.6334 - val_loss: 0.8812 - val_acc: 0.6517\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.88238 to 0.88123, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 27/100\n",
            "28709/28709 [==============================] - 18s 624us/step - loss: 0.9196 - acc: 0.6362 - val_loss: 0.8725 - val_acc: 0.6636\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.88123 to 0.87246, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 28/100\n",
            "28709/28709 [==============================] - 18s 627us/step - loss: 0.9157 - acc: 0.6369 - val_loss: 0.8825 - val_acc: 0.6570\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.87246\n",
            "Epoch 29/100\n",
            "28709/28709 [==============================] - 18s 625us/step - loss: 0.9092 - acc: 0.6431 - val_loss: 0.8621 - val_acc: 0.6523\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.87246 to 0.86211, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 30/100\n",
            "28709/28709 [==============================] - 18s 628us/step - loss: 0.8983 - acc: 0.6446 - val_loss: 0.8647 - val_acc: 0.6702\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.86211\n",
            "Epoch 31/100\n",
            "28709/28709 [==============================] - 18s 624us/step - loss: 0.8911 - acc: 0.6497 - val_loss: 0.8723 - val_acc: 0.6629\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.86211\n",
            "Epoch 32/100\n",
            "28709/28709 [==============================] - 18s 625us/step - loss: 0.8976 - acc: 0.6456 - val_loss: 0.8657 - val_acc: 0.6669\n",
            "\n",
            "Epoch 00032: ReduceLROnPlateau reducing learning rate to 8.999999772640876e-05.\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.86211\n",
            "Epoch 33/100\n",
            "28709/28709 [==============================] - 18s 624us/step - loss: 0.8844 - acc: 0.6528 - val_loss: 0.8626 - val_acc: 0.6748\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.86211\n",
            "Epoch 34/100\n",
            "28709/28709 [==============================] - 18s 624us/step - loss: 0.8790 - acc: 0.6528 - val_loss: 0.8500 - val_acc: 0.6715\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.86211 to 0.84999, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 35/100\n",
            "28709/28709 [==============================] - 18s 624us/step - loss: 0.8746 - acc: 0.6561 - val_loss: 0.8505 - val_acc: 0.6742\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.84999\n",
            "Epoch 36/100\n",
            "28709/28709 [==============================] - 18s 624us/step - loss: 0.8689 - acc: 0.6578 - val_loss: 0.8524 - val_acc: 0.6755\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.84999\n",
            "Epoch 37/100\n",
            "28709/28709 [==============================] - 18s 624us/step - loss: 0.8663 - acc: 0.6602 - val_loss: 0.8391 - val_acc: 0.6801\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.84999 to 0.83908, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 38/100\n",
            "28709/28709 [==============================] - 18s 628us/step - loss: 0.8599 - acc: 0.6599 - val_loss: 0.8599 - val_acc: 0.6722\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.83908\n",
            "Epoch 39/100\n",
            "28709/28709 [==============================] - 18s 624us/step - loss: 0.8553 - acc: 0.6667 - val_loss: 0.8350 - val_acc: 0.6781\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.83908 to 0.83504, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 40/100\n",
            "28709/28709 [==============================] - 18s 623us/step - loss: 0.8545 - acc: 0.6656 - val_loss: 0.8431 - val_acc: 0.6781\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.83504\n",
            "Epoch 41/100\n",
            "28709/28709 [==============================] - 18s 623us/step - loss: 0.8487 - acc: 0.6664 - val_loss: 0.8326 - val_acc: 0.6828\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.83504 to 0.83256, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 42/100\n",
            "28709/28709 [==============================] - 18s 624us/step - loss: 0.8451 - acc: 0.6701 - val_loss: 0.8455 - val_acc: 0.6801\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.83256\n",
            "Epoch 43/100\n",
            "28709/28709 [==============================] - 18s 625us/step - loss: 0.8471 - acc: 0.6670 - val_loss: 0.8321 - val_acc: 0.6901\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.83256 to 0.83209, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 44/100\n",
            "28709/28709 [==============================] - 18s 625us/step - loss: 0.8477 - acc: 0.6698 - val_loss: 0.8285 - val_acc: 0.6801\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.83209 to 0.82847, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 45/100\n",
            "28709/28709 [==============================] - 18s 624us/step - loss: 0.8336 - acc: 0.6736 - val_loss: 0.8254 - val_acc: 0.6801\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.82847 to 0.82537, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 46/100\n",
            "28709/28709 [==============================] - 18s 624us/step - loss: 0.8341 - acc: 0.6737 - val_loss: 0.8260 - val_acc: 0.6828\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.82537\n",
            "Epoch 47/100\n",
            "28709/28709 [==============================] - 18s 627us/step - loss: 0.8263 - acc: 0.6758 - val_loss: 0.8217 - val_acc: 0.6755\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.82537 to 0.82170, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 48/100\n",
            "28709/28709 [==============================] - 18s 626us/step - loss: 0.8251 - acc: 0.6757 - val_loss: 0.8268 - val_acc: 0.6841\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.82170\n",
            "Epoch 49/100\n",
            "28709/28709 [==============================] - 18s 623us/step - loss: 0.8230 - acc: 0.6750 - val_loss: 0.8339 - val_acc: 0.6742\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.82170\n",
            "Epoch 50/100\n",
            "28709/28709 [==============================] - 18s 623us/step - loss: 0.8190 - acc: 0.6805 - val_loss: 0.8311 - val_acc: 0.6821\n",
            "\n",
            "Epoch 00050: ReduceLROnPlateau reducing learning rate to 8.100000122794882e-05.\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.82170\n",
            "Epoch 51/100\n",
            "28709/28709 [==============================] - 18s 623us/step - loss: 0.8109 - acc: 0.6814 - val_loss: 0.8166 - val_acc: 0.6914\n",
            "\n",
            "Epoch 00051: val_loss improved from 0.82170 to 0.81663, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 52/100\n",
            "28709/28709 [==============================] - 18s 624us/step - loss: 0.8074 - acc: 0.6839 - val_loss: 0.8187 - val_acc: 0.6854\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.81663\n",
            "Epoch 53/100\n",
            "28709/28709 [==============================] - 18s 622us/step - loss: 0.8064 - acc: 0.6837 - val_loss: 0.8188 - val_acc: 0.6861\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.81663\n",
            "Epoch 54/100\n",
            "28709/28709 [==============================] - 18s 621us/step - loss: 0.8045 - acc: 0.6853 - val_loss: 0.8065 - val_acc: 0.6974\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.81663 to 0.80649, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 55/100\n",
            "28709/28709 [==============================] - 18s 623us/step - loss: 0.8052 - acc: 0.6848 - val_loss: 0.8176 - val_acc: 0.6967\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.80649\n",
            "Epoch 56/100\n",
            "28709/28709 [==============================] - 18s 621us/step - loss: 0.7938 - acc: 0.6900 - val_loss: 0.8169 - val_acc: 0.6921\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.80649\n",
            "Epoch 57/100\n",
            "28709/28709 [==============================] - 18s 620us/step - loss: 0.7993 - acc: 0.6876 - val_loss: 0.8144 - val_acc: 0.6940\n",
            "\n",
            "Epoch 00057: ReduceLROnPlateau reducing learning rate to 7.289999848580919e-05.\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.80649\n",
            "Epoch 58/100\n",
            "28709/28709 [==============================] - 18s 621us/step - loss: 0.7909 - acc: 0.6910 - val_loss: 0.8133 - val_acc: 0.6987\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.80649\n",
            "Epoch 59/100\n",
            "28709/28709 [==============================] - 18s 623us/step - loss: 0.7879 - acc: 0.6946 - val_loss: 0.8094 - val_acc: 0.6940\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.80649\n",
            "Epoch 60/100\n",
            "28709/28709 [==============================] - 18s 621us/step - loss: 0.7821 - acc: 0.6947 - val_loss: 0.8194 - val_acc: 0.6914\n",
            "\n",
            "Epoch 00060: ReduceLROnPlateau reducing learning rate to 6.56100019114092e-05.\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.80649\n",
            "Epoch 61/100\n",
            "28709/28709 [==============================] - 18s 622us/step - loss: 0.7801 - acc: 0.6962 - val_loss: 0.8014 - val_acc: 0.6947\n",
            "\n",
            "Epoch 00061: val_loss improved from 0.80649 to 0.80145, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 62/100\n",
            "28709/28709 [==============================] - 18s 624us/step - loss: 0.7795 - acc: 0.6938 - val_loss: 0.8009 - val_acc: 0.6894\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.80145 to 0.80090, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 63/100\n",
            "28709/28709 [==============================] - 18s 623us/step - loss: 0.7734 - acc: 0.6985 - val_loss: 0.8014 - val_acc: 0.6967\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.80090\n",
            "Epoch 64/100\n",
            "28709/28709 [==============================] - 18s 624us/step - loss: 0.7722 - acc: 0.6988 - val_loss: 0.8094 - val_acc: 0.6881\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.80090\n",
            "Epoch 65/100\n",
            "28709/28709 [==============================] - 18s 621us/step - loss: 0.7682 - acc: 0.6999 - val_loss: 0.8008 - val_acc: 0.6987\n",
            "\n",
            "Epoch 00065: ReduceLROnPlateau reducing learning rate to 5.904900172026828e-05.\n",
            "\n",
            "Epoch 00065: val_loss improved from 0.80090 to 0.80082, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 66/100\n",
            "28709/28709 [==============================] - 18s 622us/step - loss: 0.7724 - acc: 0.6984 - val_loss: 0.8032 - val_acc: 0.7013\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.80082\n",
            "Epoch 67/100\n",
            "28709/28709 [==============================] - 18s 621us/step - loss: 0.7646 - acc: 0.7021 - val_loss: 0.8079 - val_acc: 0.6927\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.80082\n",
            "Epoch 68/100\n",
            "28709/28709 [==============================] - 18s 621us/step - loss: 0.7602 - acc: 0.7048 - val_loss: 0.7967 - val_acc: 0.6960\n",
            "\n",
            "Epoch 00068: val_loss improved from 0.80082 to 0.79671, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model.h5\n",
            "Epoch 69/100\n",
            "28709/28709 [==============================] - 18s 624us/step - loss: 0.7576 - acc: 0.7056 - val_loss: 0.7988 - val_acc: 0.7007\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.79671\n",
            "Epoch 70/100\n",
            "28709/28709 [==============================] - 18s 622us/step - loss: 0.7579 - acc: 0.7039 - val_loss: 0.7982 - val_acc: 0.6934\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.79671\n",
            "Epoch 71/100\n",
            "28709/28709 [==============================] - 18s 620us/step - loss: 0.7600 - acc: 0.7044 - val_loss: 0.7967 - val_acc: 0.6894\n",
            "\n",
            "Epoch 00071: ReduceLROnPlateau reducing learning rate to 5.314410154824145e-05.\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.79671\n",
            "Epoch 72/100\n",
            "28709/28709 [==============================] - 18s 624us/step - loss: 0.7442 - acc: 0.7094 - val_loss: 0.8008 - val_acc: 0.7013\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.79671\n",
            "Epoch 73/100\n",
            "28709/28709 [==============================] - 18s 622us/step - loss: 0.7544 - acc: 0.7056 - val_loss: 0.8076 - val_acc: 0.6993\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.79671\n",
            "Epoch 74/100\n",
            "28709/28709 [==============================] - 18s 622us/step - loss: 0.7461 - acc: 0.7067 - val_loss: 0.8019 - val_acc: 0.6887\n",
            "\n",
            "Epoch 00074: ReduceLROnPlateau reducing learning rate to 4.7829690083744934e-05.\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.79671\n",
            "Epoch 75/100\n",
            "28709/28709 [==============================] - 18s 624us/step - loss: 0.7505 - acc: 0.7087 - val_loss: 0.8022 - val_acc: 0.6901\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.79671\n",
            "Epoch 76/100\n",
            "28709/28709 [==============================] - 18s 623us/step - loss: 0.7469 - acc: 0.7055 - val_loss: 0.8034 - val_acc: 0.6927\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.79671\n",
            "Epoch 00076: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f491dbd5630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKibNUo0OAEN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "7ada327c-cb3e-4284-c3dd-a7679d00ab53"
      },
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Conv2D(input_shape=list((width,height)) + [1], filters=num_filters,\n",
        "                  kernel_size=kernel_size, activation='relu', data_format='channels_last', kernel_regularizer=l2(0.01)))\n",
        "model2.add(Conv2D(filters=num_filters, kernel_size=kernel_size, activation='relu', data_format='channels_last', padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPooling2D())\n",
        "model2.add(Dropout(0.5))\n",
        "\n",
        "model2.add(Conv2D(filters=num_filters, kernel_size=kernel_size, activation='relu', data_format='channels_last', padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Conv2D(filters=num_filters, kernel_size=kernel_size, activation='relu', data_format='channels_last', padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPooling2D())\n",
        "model2.add(Dropout(0.5))\n",
        "\n",
        "model2.add(Conv2D(filters=num_filters, kernel_size=kernel_size, activation='relu', data_format='channels_last', padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Conv2D(filters=num_filters, kernel_size=kernel_size, activation='relu', data_format='channels_last', padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPooling2D())\n",
        "model2.add(Dropout(0.5))\n",
        "\n",
        "model2.add(Flatten())\n",
        "\n",
        "emotion_dict = {0: \"neutra\", 1: \"feliz\", 2: \"triste\", 3: \"surpreso\", 4: \"bravo\"}\n",
        "model2.add(Dense(units=len(emotion_dict.keys()), activation=\"softmax\"))\n",
        "model2.summary()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_16 (Conv2D)           (None, 45, 45, 10)        170       \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 45, 45, 10)        1610      \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 45, 45, 10)        40        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 22, 22, 10)        0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 22, 22, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 22, 22, 10)        1610      \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 22, 22, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 22, 22, 10)        1610      \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 22, 22, 10)        40        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 11, 11, 10)        0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 11, 11, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 11, 11, 10)        1610      \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 11, 11, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 11, 11, 10)        1610      \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 11, 11, 10)        40        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 10)          0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 5, 5, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 1255      \n",
            "=================================================================\n",
            "Total params: 9,675\n",
            "Trainable params: 9,575\n",
            "Non-trainable params: 100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0Dc7-M_MFZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2.compile(optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7), loss=categorical_crossentropy, metrics=['accuracy'])\n",
        "checkpointer = ModelCheckpoint(MODELPATH2, monitor='val_loss', verbose=1, save_best_only=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YD9wtvhODie",
        "colab_type": "code",
        "outputId": "a955683f-3985-4983-ef60-1c9a82a50ff1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model2.fit(np.array(X_train), np.array(y_train),\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(np.array(X_test), np.array(y_test)),\n",
        "          shuffle=True,\n",
        "          callbacks=[ReduceLROnPlateau(), EarlyStopping(patience=3), checkpointer])\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 28709 samples, validate on 1510 samples\n",
            "Epoch 1/100\n",
            "28709/28709 [==============================] - 12s 427us/step - loss: 2.0161 - acc: 0.2617 - val_loss: 1.6051 - val_acc: 0.2894\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.60514, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model_inn_drop.h5\n",
            "Epoch 2/100\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 1.6606 - acc: 0.3002 - val_loss: 1.6144 - val_acc: 0.2993\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 1.60514\n",
            "Epoch 3/100\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 1.5625 - acc: 0.3302 - val_loss: 1.4665 - val_acc: 0.3709\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.60514 to 1.46651, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model_inn_drop.h5\n",
            "Epoch 4/100\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 1.4671 - acc: 0.3725 - val_loss: 1.5097 - val_acc: 0.3212\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 1.46651\n",
            "Epoch 5/100\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 1.4022 - acc: 0.4125 - val_loss: 1.3213 - val_acc: 0.4675\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.46651 to 1.32128, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model_inn_drop.h5\n",
            "Epoch 6/100\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 1.3584 - acc: 0.4400 - val_loss: 1.3272 - val_acc: 0.4589\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 1.32128\n",
            "Epoch 7/100\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 1.3267 - acc: 0.4527 - val_loss: 1.2254 - val_acc: 0.5159\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.32128 to 1.22539, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model_inn_drop.h5\n",
            "Epoch 8/100\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 1.2906 - acc: 0.4722 - val_loss: 1.2460 - val_acc: 0.4934\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.22539\n",
            "Epoch 9/100\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 1.2537 - acc: 0.4910 - val_loss: 1.2173 - val_acc: 0.4947\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.22539 to 1.21728, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model_inn_drop.h5\n",
            "Epoch 10/100\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 1.2284 - acc: 0.5012 - val_loss: 1.1197 - val_acc: 0.5682\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.21728 to 1.11968, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model_inn_drop.h5\n",
            "Epoch 11/100\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 1.2019 - acc: 0.5143 - val_loss: 1.1149 - val_acc: 0.5589\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.11968 to 1.11490, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model_inn_drop.h5\n",
            "Epoch 12/100\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 1.1810 - acc: 0.5246 - val_loss: 1.0605 - val_acc: 0.5874\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.11490 to 1.06049, saving model to /content/drive/My Drive/Colab Notebooks/desafioBB/models/model_inn_drop.h5\n",
            "Epoch 13/100\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 1.1583 - acc: 0.5309 - val_loss: 1.0821 - val_acc: 0.5907\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 1.06049\n",
            "Epoch 14/100\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 1.1537 - acc: 0.5331 - val_loss: 1.0920 - val_acc: 0.5715\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 1.06049\n",
            "Epoch 15/100\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 1.1391 - acc: 0.5410 - val_loss: 1.1887 - val_acc: 0.5265\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.06049\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f48c22d6470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}